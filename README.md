# Excalibur_OCRmodel
# OCR Classification & Recognition System

This repository contains two main components:
1. **Classification model** â€“ to identify the type of image and determine which OCR engine to use.
2. **OCR models** â€“ including **PaddleOCR** and **NanoNet**, used for text extraction and post-processing.

---

## âš™ï¸ Environment Requirements

| Component | Python Version | Notes |
|------------|----------------|--------|
| `classification` (image classifier) | **Python 3.10** | Uses TensorFlow/Keras-based model (`keras_model.h5`) |
| `ocr modules` (PaddleOCR, NanoNet) | **Python 3.13** | Uses PaddleOCR, OpenCV, PIL, NumPy, etc. |

> âš ï¸ Itâ€™s recommended to create two separate environments to avoid dependency conflicts.



---

## ğŸ“ Folder Structure

project_root/
â”‚
â”œâ”€â”€Checkpoint
â”‚ â””â”€â”€ keras_model.h5 # Pretrained classifier model
â”œâ”€â”€ classification.ipynb # Script to classify images
â”œâ”€â”€ Paddle.ipynb # PaddleOCR class definition
â”œâ”€â”€ VLM.ipynb # NanoNet OCR class definition
â”œâ”€â”€ utils.py # Image preprocessing functions
â”œâ”€â”€ images/ # Input images for classification
â”‚
â””â”€â”€ README.md

---

## Image Path Configuration

Make sure to define your **image paths** properly in your scripts.

```python
# Example (for PaddleOCR or NanoNet)
img_path = r"D:\Classification\images\sample.jpg"
txt_dir  = r"D:\Classification\results"

---

## How to Run

1. **Open Jupyter Notebook or VSCode Notebook interface.**  
2. **Run notebooks in order** as listed below:

   1ï¸âƒ£ `classification.ipynb`  
   â†’ Classifies the document and decides which OCR model should be used.  
   Output: saves classification results inside `results/classification/`.

   2ï¸âƒ£ `paddle_ocr.ipynb`  
   â†’ Performs OCR using PaddleOCR model.  
   Output: saves text results and processed images to `results/paddle/`.

   3ï¸âƒ£ `nanonet_ocr.ipynb`  
   â†’ Performs OCR using Nanonet model.  
   Output: saves text results and processed images to `results/nanonet/`.

   4ï¸âƒ£ `evaluation.ipynb`  
   â†’ Compares OCR outputs from both models and evaluates accuracy.  
   Output: combined final result inside `results/merged/`.

---
