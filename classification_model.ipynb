{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LIBRARY REQUIREMENTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#MODEL CLASSIFICATION\n",
        "\n",
        "%pip install tensorflow==2.15.1 keras==2.15.0 pillow numpy  \n",
        "#DOCSTRANGE_NANONETSOCR\n",
        "%pip install -q 'git+https://github.com/facebookresearch/detectron2.git'\n",
        "%pip install opencv-python-headless ultralytics\n",
        "%pip install docstrange\n",
        "%pip install torch==2.2.1 torchvision==0.17.1 torchaudio==2.2.1 --index-url https://download.pytorch.org/whl/cu121\n",
        "%pip install tqdm pyyaml matplotlib scikit-image shapely\n",
        "%pip install imgaug pycocotools\n",
        "#PADDLE\n",
        "%pip install paddlepaddle\n",
        "%pip install paddleocr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Pzdeos9SqjK"
      },
      "outputs": [],
      "source": [
        "!python --version\n",
        "!python3.10 - <<'PY'\n",
        "import sys, tensorflow as tf, keras, PIL\n",
        "print(\"Python:\", sys.version)\n",
        "print(\"TensorFlow:\", tf.__version__)\n",
        "print(\"Keras:\", keras.__version__)\n",
        "print(\"Pillow:\", PIL.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CLASSIFICATION MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from keras.models import load_model\n",
        "from PIL import Image, ImageOps\n",
        "import numpy as np\n",
        "\n",
        "# ==== C·∫§U H√åNH ====\n",
        "# Th∆∞ m·ª•c ch·ª©a ·∫£nh\n",
        "IMAGE_FOLDER = r\"D:\\New folder\\Classification\\images\" \n",
        "# ƒê∆∞·ªùng d·∫´n model\n",
        "MODEL_PATH = r\"D:\\New folder\\Classification\\keras_model.h5\"\n",
        "# ƒê∆∞·ªùng d·∫´n labels\n",
        "LABEL_PATH = r\"D:\\New folder\\Classification\\labels.txt\"\n",
        "\n",
        "# ==== CHU·∫®N B·ªä M√îI TR∆Ø·ªúNG ====\n",
        "np.set_printoptions(suppress=True)\n",
        "model = load_model(MODEL_PATH, compile=False)\n",
        "class_names = open(LABEL_PATH, \"r\").readlines()\n",
        "\n",
        "#============COUNT==============\n",
        "bill_count = 0\n",
        "no_bill_count = 0\n",
        "\n",
        "print(\"Model & labels loaded successfully!\")\n",
        "\n",
        "# ==== DUY·ªÜT QUA T·ª™NG ·∫¢NH ====\n",
        "for filename in os.listdir(IMAGE_FOLDER):\n",
        "    if not filename.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
        "        continue  # b·ªè qua file kh√¥ng ph·∫£i ·∫£nh\n",
        "\n",
        "    image_path = os.path.join(IMAGE_FOLDER, filename)\n",
        "    print(f\"\\n--- Processing: {filename} ---\")\n",
        "\n",
        "    try:\n",
        "        # Load ·∫£nh\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "        # Resize & normalize\n",
        "        size = (224, 224)\n",
        "        image = ImageOps.fit(image, size, Image.Resampling.LANCZOS)\n",
        "        image_array = np.asarray(image)\n",
        "        normalized_image_array = (image_array.astype(np.float32) / 127.5) - 1\n",
        "\n",
        "        # D·ª± ƒëo√°n\n",
        "        data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n",
        "        data[0] = normalized_image_array\n",
        "        prediction = model.predict(data)\n",
        "        index = np.argmax(prediction)\n",
        "        class_name = class_names[index].strip()\n",
        "        confidence_score = prediction[0][index]\n",
        "\n",
        "        print(f\"‚Üí Class: {class_name} | Confidence: {confidence_score:.4f}\")\n",
        "\n",
        "        # ==== X·ª¨ L√ù THEO NH√ÉN ====\n",
        "        if class_name == \"1 Bill\":\n",
        "            # (bill)\n",
        "            bill_count += 1            # D√πng model Paddle\n",
        "        elif class_name == \"0 Not Bill\":\n",
        "            # N·∫øu kh√¥ng ph·∫£i h√≥a ƒë∆°n (no bill)\n",
        "            no_bill_count += 1         # D√πng model VLM\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå‚ùå‚ùå‚ùåerror in:{filename}: {e}\")\n",
        "\n",
        "\n",
        "print(\"\\n============================\")\n",
        "print(f\"T·ªïng s·ªë ·∫£nh bill: {bill_count}\")\n",
        "print(f\"T·ªïng s·ªë ·∫£nh no-bill: {no_bill_count}\")\n",
        "print(f\"T·ªïng c·ªông: {bill_count + no_bill_count}\")\n",
        "print(\"============================\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# NANONETSOCR MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, cv2, torch\n",
        "import numpy as np\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2 import model_zoo\n",
        "\n",
        "#For Docstrange\n",
        "from docstrange import DocumentExtractor\n",
        "import random\n",
        "import glob\n",
        "\n",
        "def init_segmentor(threshold=0.5, device=None):\n",
        "    cfg = get_cfg()\n",
        "    cfg.merge_from_file(model_zoo.get_config_file(\n",
        "        \"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\"))\n",
        "    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\n",
        "        \"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\")\n",
        "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = threshold\n",
        "    cfg.MODEL.DEVICE = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    return DefaultPredictor(cfg)\n",
        "\n",
        "# T·∫°o global predictor ƒë·ªÉ t√°i s·ª≠ d·ª•ng\n",
        "predictor = init_segmentor()\n",
        "\n",
        "# ===============================================================\n",
        "# üß† Function ch√≠nh: x√≥a object & l∆∞u ƒë√®\n",
        "# ===============================================================\n",
        "def remove_objects_and_save(img_path, mask_color=(255, 255, 255)):\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    D√≤ t√¨m object trong ·∫£nh, x√≥a (mask tr·∫Øng) v√πng ƒë√≥ v√† l∆∞u ƒë√® l√™n ·∫£nh g·ªëc.\n",
        "    \"\"\"\n",
        "    # ƒê·ªçc ·∫£nh\n",
        "    img = cv2.imread(img_path)\n",
        "    if img is None:\n",
        "        print(f\"[!] Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c ·∫£nh: {img_path}\")\n",
        "        return\n",
        "\n",
        "    # Detect object\n",
        "    outputs = predictor(img)\n",
        "    instances = outputs[\"instances\"].to(\"cpu\")\n",
        "\n",
        "    if not instances.has(\"pred_masks\"):\n",
        "        print(f\"[INFO] Kh√¥ng ph√°t hi·ªán mask trong ·∫£nh: {img_path}\")\n",
        "        return\n",
        "\n",
        "    masks = instances.pred_masks.numpy()  # [N, H, W]\n",
        "\n",
        "    # N·∫øu kh√¥ng c√≥ ƒë·ªëi t∆∞·ª£ng n√†o\n",
        "    if masks.shape[0] == 0:\n",
        "        print(f\"[INFO] ·∫¢nh kh√¥ng c√≥ object c·∫ßn x√≥a: {img_path}\")\n",
        "        return\n",
        "\n",
        "    # G·ªôp t·∫•t c·∫£ mask l·∫°i\n",
        "    combined_mask = np.any(masks, axis=0).astype(np.uint8)\n",
        "\n",
        "    # Thay v√πng mask b·∫±ng m√†u tr·∫Øng\n",
        "    img[combined_mask == 1] = mask_color\n",
        "\n",
        "    # L∆∞u ƒë√® ·∫£nh\n",
        "    cv2.imwrite(img_path, img)\n",
        "    print(f\"[DONE] ƒê√£ x√≥a object v√† l∆∞u l·∫°i: {img_path}\")\n",
        "\n",
        "\n",
        "\n",
        "def auto_split_image(img_path, diff_thresh=40, min_gap=2000):\n",
        "    \"\"\"\n",
        "    T·ª± ƒë·ªông c·∫Øt ·∫£nh d√†i theo s·ª± thay ƒë·ªïi m√†u n·ªÅn d·ªçc tr·ª•c Y.\n",
        "    L∆∞u c√°c ·∫£nh con v√†o th∆∞ m·ª•c Cropped_Images/{img_name}/.\n",
        "    ·∫¢nh ƒë∆∞·ª£c ƒë·∫∑t t√™n theo d·∫°ng: {img_name}-A1.jpg, {img_name}-A2.jpg, ...\n",
        "    \"\"\"\n",
        "    # ==== Load ·∫£nh g·ªëc ====\n",
        "    img = cv2.imread(img_path)\n",
        "    if img is None:\n",
        "        print(f\"[!] Kh√¥ng th·ªÉ ƒë·ªçc ·∫£nh: {img_path}\")\n",
        "        return\n",
        "    h, w, _ = img.shape\n",
        "    print(f\"[INFO] ·∫¢nh g·ªëc: {w}x{h}\")\n",
        "\n",
        "    # ==== L√†m m∆∞·ª£t ·∫£nh ƒë·ªÉ gi·∫£m nhi·ªÖu ch·ªØ ====\n",
        "    blur = cv2.GaussianBlur(img, (15, 15), 0)\n",
        "\n",
        "    # ==== Chuy·ªÉn sang LAB ƒë·ªÉ ·ªïn ƒë·ªãnh m√†u ====\n",
        "    lab = cv2.cvtColor(blur, cv2.COLOR_BGR2LAB)\n",
        "    mean_color = lab.mean(axis=1)  # trung b√¨nh theo chi·ªÅu ngang\n",
        "    diff = np.abs(np.diff(mean_color, axis=0)).mean(axis=1)\n",
        "\n",
        "    # ==== Chu·∫©n h√≥a & smooth ====\n",
        "    diff = cv2.GaussianBlur(diff.reshape(-1,1), (1, 21), 0).flatten()\n",
        "    diff_norm = (diff - diff.min()) / (diff.max() - diff.min() + 1e-8)\n",
        "\n",
        "    # ==== T√≠nh bi√™n b·∫±ng Sobel ƒë·ªÉ b·ªï sung th√¥ng tin c·∫•u tr√∫c ====\n",
        "    gray = cv2.cvtColor(blur, cv2.COLOR_BGR2GRAY)\n",
        "    sobel = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)\n",
        "    edge_strength = np.mean(np.abs(sobel), axis=1)\n",
        "    edge_strength = (edge_strength - edge_strength.min()) / (edge_strength.max() - edge_strength.min() + 1e-8)\n",
        "\n",
        "    # ==== CƒÉn ch·ªânh chi·ªÅu d√†i ====\n",
        "    if edge_strength.shape[0] != diff_norm.shape[0]:\n",
        "        min_len = min(len(edge_strength), len(diff_norm))\n",
        "        edge_strength = edge_strength[:min_len]\n",
        "        diff_norm = diff_norm[:min_len]\n",
        "\n",
        "    # ==== K·∫øt h·ª£p 2 t√≠n hi·ªáu ====\n",
        "    signal = 0.7 * diff_norm + 0.3 * edge_strength\n",
        "\n",
        "    # ==== X√°c ƒë·ªãnh ranh gi·ªõi ====\n",
        "    boundaries = []\n",
        "    last_cut = 0\n",
        "    for y in range(1, len(signal)-1):\n",
        "        if signal[y] > 0.6 and signal[y] == max(signal[y-3:y+3]):\n",
        "            if y - last_cut > min_gap:\n",
        "                boundaries.append(y)\n",
        "                last_cut = y\n",
        "\n",
        "    if not boundaries:\n",
        "        print(\"[!] Kh√¥ng ph√°t hi·ªán ƒë∆∞·ª£c ranh gi·ªõi r√µ r√†ng, ·∫£nh kh√¥ng ƒë∆∞·ª£c c·∫Øt.\")\n",
        "        boundaries = [h]\n",
        "\n",
        "    # ==== Crop v√† l∆∞u ====\n",
        "    base_name = os.path.splitext(os.path.basename(img_path))[0]\n",
        "    save_dir = f\"Cropped_Images/{base_name}\"\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    prev_y = 0\n",
        "    count = 1\n",
        "    for y in boundaries + [h]:\n",
        "        crop = img[prev_y:y, :]\n",
        "        if crop.shape[0] > 50:  # b·ªè qua crop qu√° nh·ªè\n",
        "            save_path = os.path.join(save_dir, f\"{base_name}-A{count}.jpg\")\n",
        "            cv2.imwrite(save_path, crop)\n",
        "            print(f\"[+] Saved: {save_path} ({crop.shape[1]}x{crop.shape[0]})\")\n",
        "            count += 1\n",
        "        prev_y = y\n",
        "\n",
        "    print(f\"[DONE] ƒê√£ l∆∞u {count-1} ·∫£nh con v√†o th∆∞ m·ª•c: {save_dir}\")\n",
        "    return save_dir\n",
        "\n",
        "\n",
        "#Creating many extractors to use more API :))\n",
        "extractor1 = DocumentExtractor(\n",
        "      preserve_layout=True,\n",
        "      api_key=\"7138f093-9836-11f0-a5f8-6abdbfc750c5\"\n",
        "  )\n",
        "extractor2 = DocumentExtractor(\n",
        "      preserve_layout=True,\n",
        "      api_key=\"7138f093-9836-11f0-a5f8-6abdbfc750c5\"\n",
        "  )\n",
        "extractor3 = DocumentExtractor(\n",
        "      preserve_layout=True,\n",
        "      api_key=\"7138f093-9836-11f0-a5f8-6abdbfc750c5\"\n",
        "  )\n",
        "extractor4 = DocumentExtractor(\n",
        "      preserve_layout=True,\n",
        "      api_key=\"7138f093-9836-11f0-a5f8-6abdbfc750c5\"\n",
        "  )\n",
        "extractors_list = [extractor1,extractor2,extractor3,extractor4]\n",
        "\n",
        "\n",
        "def docstrange_ocr_short(img_path,output_path):\n",
        "  extractor = random.choice(extractors_list)\n",
        "  remove_objects_and_save(img_path)\n",
        "  result = extractor.extract(img_path)\n",
        "\n",
        "  schema = {\n",
        "      \"text_top_to_bottom\": \"string\\nstring\"\n",
        "  }\n",
        "\n",
        "  os.makedirs(output_path, exist_ok=True)\n",
        "  output_text = result.extract_data(json_schema=schema)[\"structured_data\"][\"text_top_to_bottom\"]\n",
        "  output_path = output_path + \"/\" + os.path.splitext(os.path.basename(img_path))[0] +\".txt\" #L·∫•y t√™n ·∫£nh\n",
        "\n",
        "  with open(output_path,mode=\"w\") as f:\n",
        "    f.write(output_text)\n",
        "\n",
        "def docstrange_ocr_long(long_img_path, output_path):\n",
        "    extractor = random.choice(extractors_list)\n",
        "\n",
        "    img_name = \"/\" + os.path.basename(long_img_path) + \".txt\"  # long_img_path l√† folder ch·ª©a c√°c ·∫£nh crop\n",
        "    schema = {\"text_top_to_bottom\": \"string\\nstring\"}\n",
        "\n",
        "    # T·∫°o output folder (n·∫øu ch∆∞a c√≥)\n",
        "    os.makedirs(output_path, exist_ok=True)\n",
        "    output_file = output_path + img_name\n",
        "\n",
        "    # ‚úÖ L·∫•y t·∫•t c·∫£ ·∫£nh h·ª£p l·ªá trong folder\n",
        "    img_extensions = (\"*.png\", \"*.jpg\", \"*.jpeg\", \"*.webp\")\n",
        "    img_files = []\n",
        "    for ext in img_extensions:\n",
        "        img_files.extend(glob.glob(os.path.join(long_img_path, ext)))\n",
        "\n",
        "    # ‚úÖ OCR t·ª´ng ·∫£nh v√† n·ªëi text v√†o file duy nh·∫•t\n",
        "    for img_path in sorted(img_files):  # s·∫Øp x·∫øp cho ƒë√∫ng th·ª© t·ª±\n",
        "        remove_objects_and_save(img_path)\n",
        "        result = extractor.extract(img_path)\n",
        "        output_text = result.extract_data(json_schema=schema)[\"structured_data\"][\"text_top_to_bottom\"]\n",
        "\n",
        "        with open(output_file, mode=\"a\", encoding=\"utf-8\") as f:\n",
        "            f.write(output_text + \"\\n\")\n",
        "\n",
        "    print(f\"‚úÖ Saved combined OCR text to: {output_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PADDLE OCR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#### PADDLE OCR \n",
        "class PaddleOCRmodel:\n",
        "    def __init__(self, lang=\"korean\"):\n",
        "        \"\"\"\n",
        "        Initializes the PaddleOCR model.\n",
        "        Args:\n",
        "            lang (str): The language for OCR (default is \"korean\").\n",
        "        \"\"\"\n",
        "        self.ocr = PaddleOCR(\n",
        "            use_doc_orientation_classify=False,\n",
        "            use_doc_unwarping=False,\n",
        "            use_textline_orientation=False,\n",
        "            lang=lang\n",
        "        )\n",
        "    \n",
        "    def run_ocr_and_save_results(self, image_file, txt_dir):\n",
        "        \"\"\"\n",
        "        Runs PaddleOCR on a single image file and saves the results.\n",
        "        Args:\n",
        "            image_file (str): Path to the image file to process.\n",
        "            txt_dir (str): The directory to save the extracted text file.\n",
        "        Returns:\n",
        "            str: Path to the created text file, or None if failed.\n",
        "        \"\"\"\n",
        "        if not image_file:\n",
        "            print(\"No image file provided for OCR processing.\")\n",
        "            return None\n",
        "            \n",
        "        if not os.path.exists(image_file):\n",
        "            print(f\"Image file does not exist: {image_file}\")\n",
        "            return None\n",
        "            \n",
        "        os.makedirs(txt_dir, exist_ok=True)\n",
        "        \n",
        "        try:\n",
        "            # Read image using cv2 to ensure proper format\n",
        "            import cv2\n",
        "            img = cv2.imread(image_file)\n",
        "            if img is None:\n",
        "                print(f\"Failed to read image: {image_file}\")\n",
        "                return None\n",
        "            \n",
        "            # Apply preprocessing if utils is available\n",
        "            try:\n",
        "                import ExcalibURA_OCR.utils as utils\n",
        "                img = utils.experiment_gamma_correction(img)  # Pass image data, not path\n",
        "            except ImportError:\n",
        "                print(\"Utils not available, using original image\")\n",
        "            except Exception as e:\n",
        "                print(f\"Preprocessing failed, using original image: {e}\")\n",
        "                img = cv2.imread(image_file)  # Reload original\n",
        "            \n",
        "            # Run OCR with the image data\n",
        "            result = self.ocr.predict(img)  # Use ocr() method directly\n",
        "            \n",
        "            # Get base name for output files\n",
        "            base_name = os.path.splitext(os.path.basename(image_file))[0]\n",
        "            \n",
        "            if not result or not result[0]:\n",
        "                print(f\"No OCR results for {image_file}\")\n",
        "                # Create empty text file\n",
        "                txt_output_path = os.path.join(txt_dir, f\"{base_name}.txt\")\n",
        "                with open(txt_output_path, 'w', encoding='utf-8') as f:\n",
        "                    f.write('')\n",
        "                return txt_output_path\n",
        "            \n",
        "            # Extract text from OCR results\n",
        "            extracted_texts = []\n",
        "            for line in result[0]:\n",
        "                if len(line) >= 2:\n",
        "                    text = line[1][0]  # Get the text from OCR result\n",
        "                    confidence = line[1][1]  # Get confidence score\n",
        "                    if confidence > 0.5:  # Filter low confidence results\n",
        "                        extracted_texts.append(text)\n",
        "            \n",
        "            # Create text file in the specified directory\n",
        "            txt_output_path = os.path.join(txt_dir, f\"{base_name}.txt\")\n",
        "            with open(txt_output_path, 'w', encoding='utf-8') as f:\n",
        "                for text in extracted_texts:\n",
        "                    f.write(f\"{text}\\n\")\n",
        "            \n",
        "            print(f\"‚úÖ OCR completed for {base_name}\")\n",
        "            return txt_output_path\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error processing {image_file}: {str(e)}\")\n",
        "            # Create empty file on error\n",
        "            try:\n",
        "                base_name = os.path.splitext(os.path.basename(image_file))[0]\n",
        "                txt_output_path = os.path.join(txt_dir, f\"{base_name}.txt\")\n",
        "                with open(txt_output_path, 'w', encoding='utf-8') as f:\n",
        "                    f.write('')\n",
        "                return txt_output_path\n",
        "            except:\n",
        "                return None\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MAIN\n",
        "### PADDLE IS WRITTEN IN FILE .PY SO YOU HAVE IMPLEMENT THE CODE IN .PY FILES NOT THE \n",
        "## THE PADDLE ALSO USE THE utils.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "### Main function\n",
        "def main():\n",
        "    IMAGE_FOLDER_DIR = \"/content/drive/MyDrive/Chung_Innnovation/PHASE2/images_hyecho\"\n",
        "    FOLDER_NAME = os.path.basename(IMAGE_FOLDER_DIR)\n",
        "    SAVE_DIR = \"/content/drive/MyDrive/Chung_Innnovation/PHASE2/\" + \"Result_Text/\" + FOLDER_NAME\n",
        "    os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "    error_log_path = os.path.join(SAVE_DIR, \"error.txt\")\n",
        "\n",
        "    # =========================================================\n",
        "    # C√°c ƒëu√¥i ·∫£nh h·ª£p l·ªá\n",
        "    VALID_EXTENSIONS = (\".jpg\", \".jpeg\", \".png\", \".webp\")\n",
        "\n",
        "    # =========================================================\n",
        "    error_files = []\n",
        "\n",
        "    for img_path in glob.glob(IMAGE_FOLDER_DIR + \"/*.*\"):\n",
        "        ext = os.path.splitext(img_path)[1].lower()\n",
        "\n",
        "        # üß© 1Ô∏è‚É£ B·ªè qua file kh√¥ng h·ª£p l·ªá\n",
        "        if ext not in VALID_EXTENSIONS:\n",
        "            error_files.append(f\"‚ùå Unsupported file type: {img_path}\")\n",
        "            continue\n",
        "\n",
        "        # üß© 2Ô∏è‚É£ ƒê·ªçc ·∫£nh\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is None:\n",
        "            error_files.append(f\"‚ö†Ô∏è Cannot read image: {img_path}\")\n",
        "            continue\n",
        "\n",
        "        # üß© 3Ô∏è‚É£ Ki·ªÉm tra chi·ªÅu cao ·∫£nh\n",
        "        height, width = img.shape[:2]\n",
        "\n",
        "        try:\n",
        "            if int(height) >= 5000:\n",
        "                long_img_path = auto_split_image(img_path, diff_thresh=40, min_gap=2000)\n",
        "                docstrange_ocr_long(long_img_path, output_path=SAVE_DIR)\n",
        "            else:\n",
        "                docstrange_ocr_short(img_path, output_path=SAVE_DIR)\n",
        "        except Exception as e:\n",
        "            error_files.append(f\"üí• Error processing {img_path}: {str(e)}\")\n",
        "\n",
        "    # =========================================================\n",
        "    # Ghi danh s√°ch l·ªói ra file\n",
        "    if error_files:\n",
        "        with open(error_log_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(\"\\n\".join(error_files))\n",
        "        print(f\"‚ö†Ô∏è Some files skipped or failed. See log: {error_log_path}\")\n",
        "    else:\n",
        "        print(\"‚úÖ All images processed successfully!\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
