{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e3850c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#DOCSTRANGE_NANONETSOCR \n",
    "%pip install -q 'git+https://github.com/facebookresearch/detectron2.git'\n",
    "%pip install opencv-python-headless ultralytics \n",
    "%pip install docstrange \n",
    "%pip install torch==2.2.1 torchvision==0.17.1 torchaudio==2.2.1 --index-url https://download.pytorch.org/whl/cu121 \n",
    "%pip install tqdm pyyaml matplotlib scikit-image shapely \n",
    "%pip install imgaug pycocotools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6a7ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, cv2, torch\n",
    "import numpy as np\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "\n",
    "# For Docstrange\n",
    "from docstrange import DocumentExtractor\n",
    "import random\n",
    "import glob\n",
    "\n",
    "def init_segmentor(threshold=0.5, device=None):\n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_file(model_zoo.get_config_file(\n",
    "        \"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\"))\n",
    "    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\n",
    "        \"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\")\n",
    "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = threshold\n",
    "    cfg.MODEL.DEVICE = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    return DefaultPredictor(cfg)\n",
    "\n",
    "# Create a global predictor for reuse\n",
    "predictor = init_segmentor()\n",
    "\n",
    "# ===============================================================\n",
    "# Main function: remove objects & overwrite image\n",
    "# ===============================================================\n",
    "def remove_objects_and_save(img_path, mask_color=(255, 255, 255)):\n",
    "    \"\"\"\n",
    "    Detect objects in the image, remove (mask white) those regions, and overwrite the original image.\n",
    "    \"\"\"\n",
    "    # Read image\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        print(f\"[!] Cannot read image: {img_path}\")\n",
    "        return\n",
    "\n",
    "    # Detect objects\n",
    "    outputs = predictor(img)\n",
    "    instances = outputs[\"instances\"].to(\"cpu\")\n",
    "\n",
    "    if not instances.has(\"pred_masks\"):\n",
    "        print(f\"[INFO] No masks detected in image: {img_path}\")\n",
    "        return\n",
    "\n",
    "    masks = instances.pred_masks.numpy()  # [N, H, W]\n",
    "\n",
    "    # If no objects found\n",
    "    if masks.shape[0] == 0:\n",
    "        print(f\"[INFO] No objects to remove in image: {img_path}\")\n",
    "        return\n",
    "\n",
    "    # Combine all masks\n",
    "    combined_mask = np.any(masks, axis=0).astype(np.uint8)\n",
    "\n",
    "    # Replace mask area with white color\n",
    "    img[combined_mask == 1] = mask_color\n",
    "\n",
    "    # Save (overwrite)\n",
    "    cv2.imwrite(img_path, img)\n",
    "    print(f\"[DONE] Removed objects and saved: {img_path}\")\n",
    "\n",
    "\n",
    "def auto_split_image(img_path, diff_thresh=40, min_gap=2000):\n",
    "    \"\"\"\n",
    "    Automatically split a long image based on background color change along the Y-axis.\n",
    "    Save cropped images to Cropped_Images/{img_name}/\n",
    "    Images are named as: {img_name}-A1.jpg, {img_name}-A2.jpg, ...\n",
    "    \"\"\"\n",
    "    # ==== Load original image ====\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        print(f\"[!] Cannot read image: {img_path}\")\n",
    "        return\n",
    "    h, w, _ = img.shape\n",
    "    print(f\"[INFO] Original image: {w}x{h}\")\n",
    "\n",
    "    # ==== Smooth image to reduce text noise ====\n",
    "    blur = cv2.GaussianBlur(img, (15, 15), 0)\n",
    "\n",
    "    # ==== Convert to LAB color space for stability ====\n",
    "    lab = cv2.cvtColor(blur, cv2.COLOR_BGR2LAB)\n",
    "    mean_color = lab.mean(axis=1)  # average across width\n",
    "    diff = np.abs(np.diff(mean_color, axis=0)).mean(axis=1)\n",
    "\n",
    "    # ==== Normalize and smooth ====\n",
    "    diff = cv2.GaussianBlur(diff.reshape(-1,1), (1, 21), 0).flatten()\n",
    "    diff_norm = (diff - diff.min()) / (diff.max() - diff.min() + 1e-8)\n",
    "\n",
    "    # ==== Compute edge strength using Sobel operator ====\n",
    "    gray = cv2.cvtColor(blur, cv2.COLOR_BGR2GRAY)\n",
    "    sobel = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    edge_strength = np.mean(np.abs(sobel), axis=1)\n",
    "    edge_strength = (edge_strength - edge_strength.min()) / (edge_strength.max() - edge_strength.min() + 1e-8)\n",
    "\n",
    "    # ==== Align lengths ====\n",
    "    if edge_strength.shape[0] != diff_norm.shape[0]:\n",
    "        min_len = min(len(edge_strength), len(diff_norm))\n",
    "        edge_strength = edge_strength[:min_len]\n",
    "        diff_norm = diff_norm[:min_len]\n",
    "\n",
    "    # ==== Combine both signals ====\n",
    "    signal = 0.7 * diff_norm + 0.3 * edge_strength\n",
    "\n",
    "    # ==== Find cutting boundaries ====\n",
    "    boundaries = []\n",
    "    last_cut = 0\n",
    "    for y in range(1, len(signal)-1):\n",
    "        if signal[y] > 0.6 and signal[y] == max(signal[y-3:y+3]):\n",
    "            if y - last_cut > min_gap:\n",
    "                boundaries.append(y)\n",
    "                last_cut = y\n",
    "\n",
    "    if not boundaries:\n",
    "        print(\"[!] No clear boundaries detected, image not split.\")\n",
    "        boundaries = [h]\n",
    "\n",
    "    # ==== Crop and save ====\n",
    "    base_name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "    save_dir = f\"Cropped_Images/{base_name}\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    prev_y = 0\n",
    "    count = 1\n",
    "    for y in boundaries + [h]:\n",
    "        crop = img[prev_y:y, :]\n",
    "        if crop.shape[0] > 50:  # ignore very small crops\n",
    "            save_path = os.path.join(save_dir, f\"{base_name}-A{count}.jpg\")\n",
    "            cv2.imwrite(save_path, crop)\n",
    "            print(f\"[+] Saved: {save_path} ({crop.shape[1]}x{crop.shape[0]})\")\n",
    "            count += 1\n",
    "        prev_y = y\n",
    "\n",
    "    print(f\"[DONE] Saved {count-1} cropped images to folder: {save_dir}\")\n",
    "    return save_dir\n",
    "\n",
    "\n",
    "# Creating multiple extractors to use more API keys\n",
    "extractor1 = DocumentExtractor(\n",
    "      preserve_layout=True,\n",
    "      api_key=\"7138f093-9836-11f0-a5f8-6abdbfc750c5\"\n",
    "  )\n",
    "extractor2 = DocumentExtractor(\n",
    "      preserve_layout=True,\n",
    "      api_key=\"7138f093-9836-11f0-a5f8-6abdbfc750c5\"\n",
    "  )\n",
    "extractor3 = DocumentExtractor(\n",
    "      preserve_layout=True,\n",
    "      api_key=\"7138f093-9836-11f0-a5f8-6abdbfc750c5\"\n",
    "  )\n",
    "extractor4 = DocumentExtractor(\n",
    "      preserve_layout=True,\n",
    "      api_key=\"7138f093-9836-11f0-a5f8-6abdbfc750c5\"\n",
    "  )\n",
    "extractors_list = [extractor1, extractor2, extractor3, extractor4]\n",
    "\n",
    "\n",
    "def docstrange_ocr_short(img_path, output_path):\n",
    "    extractor = random.choice(extractors_list)\n",
    "    remove_objects_and_save(img_path)\n",
    "    result = extractor.extract(img_path)\n",
    "\n",
    "    schema = {\n",
    "        \"text_top_to_bottom\": \"string\\nstring\"\n",
    "    }\n",
    "\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    output_text = result.extract_data(json_schema=schema)[\"structured_data\"][\"text_top_to_bottom\"]\n",
    "    output_path = output_path + \"/\" + os.path.splitext(os.path.basename(img_path))[0] + \".txt\"  # get image name\n",
    "\n",
    "    with open(output_path, mode=\"w\") as f:\n",
    "        f.write(output_text)\n",
    "\n",
    "\n",
    "def docstrange_ocr_long(long_img_path, output_path):\n",
    "    extractor = random.choice(extractors_list)\n",
    "\n",
    "    img_name = \"/\" + os.path.basename(long_img_path) + \".txt\"  # long_img_path is a folder containing cropped images\n",
    "    schema = {\"text_top_to_bottom\": \"string\\nstring\"}\n",
    "\n",
    "    # Create output folder if not exist\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    output_file = output_path + img_name\n",
    "\n",
    "    # Get all valid images in folder\n",
    "    img_extensions = (\"*.png\", \"*.jpg\", \"*.jpeg\", \"*.webp\")\n",
    "    img_files = []\n",
    "    for ext in img_extensions:\n",
    "        img_files.extend(glob.glob(os.path.join(long_img_path, ext)))\n",
    "\n",
    "    # OCR each image and append text to one file\n",
    "    for img_path in sorted(img_files):  # ensure correct order\n",
    "        remove_objects_and_save(img_path)\n",
    "        result = extractor.extract(img_path)\n",
    "        output_text = result.extract_data(json_schema=schema)[\"structured_data\"][\"text_top_to_bottom\"]\n",
    "\n",
    "        with open(output_file, mode=\"a\", encoding=\"utf-8\") as f:\n",
    "            f.write(output_text + \"\\n\")\n",
    "\n",
    "    print(f\"[DONE] Saved combined OCR text to: {output_file}\")\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "# Example main script: assign paths and run functions\n",
    "# ===============================================================\n",
    "if __name__ == \"__main__\":\n",
    "    # Example: assign image path and output folder\n",
    "    img_path = r\"\\images\\no_bill\"          # Path to input image\n",
    "    output_path = r\"OCR_Results\"             # Folder to save OCR results\n",
    "\n",
    "    # Example 1: remove objects and overwrite the image\n",
    "    remove_objects_and_save(img_path)\n",
    "\n",
    "    # Example 2: split long image automatically\n",
    "    cropped_folder = auto_split_image(img_path)\n",
    "\n",
    "    # Example 3: OCR for a single short image\n",
    "    docstrange_ocr_short(img_path, output_path)\n",
    "\n",
    "    # Example 4: OCR for long image that has been split\n",
    "    if cropped_folder:\n",
    "        docstrange_ocr_long(cropped_folder, output_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
